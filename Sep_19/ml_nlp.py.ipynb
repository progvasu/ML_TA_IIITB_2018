{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to process text for ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text cannot be used as is for input to ML models\n",
    "\n",
    "We need some way of representing text in a numerical format so that a model can understand it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, sentences are broken down into tokens (words)\n",
    "\n",
    "Then each token in encoded to as integer or floating-point values for use as input to a machine learning algorithm. This is called **feature extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words Model (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW is a popularly used model for representing text documents.\n",
    "\n",
    "This model focuses simply on the occurence information of words in documents and not on any order information.\n",
    "\n",
    "This encoding represents what words are present and to what degree they are present. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary = {'how':0, 'old':1, 'thank':2, 'are':3, 'you':4, 'very':5, 'now':6, 'much':7}\n",
    "\n",
    "doc1 = \"how old are you now\"\n",
    "doc2 = \"thank you very much\"\n",
    "\n",
    "doc1_tokens = [\"how\", \"old\", \"are\", \"you\", \"now\"]\n",
    "doc2_tokens = [\"thank\", \"you\", \"very\", \"much\"]\n",
    "\n",
    "docs = [ [1, 1, 0, 1, 1, 0, 1, 0], \n",
    "         [0, 0, 1, 0, 1, 1, 0, 1] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn library provides 3 different schemes for achieving BoW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'brown': 0, u'lazy': 4, u'jumped': 3, u'over': 5, u'fox': 2, u'dog': 1, u'quick': 6, u'the': 7}\n",
      "(1, 8)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[1 1 1 1 1 1 1 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# list of text documents\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\"]\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "# encode document\n",
    "vector = vectorizer.transform(text)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "text2 = [\"the fox is brown\"]\n",
    "vector = vectorizer.transform(text2)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words occur too frequently!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ex : a, an, the, is, for, to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, these words need not add any value to the content of the text documents. \n",
    "\n",
    "To solve, this TF-IDF is very popularly used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF is an acronym for **Term Frequency - Inverse Document Frequency**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Term Frequency**: This summarizes how often a given word appears within a document\n",
    "\n",
    "**Inverse Document Frequency**: This downscales words that appear a lot across documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a score attributed to each word which takes into account its frequency while discounting its document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF(t) = No of times term t apprears in a document / Total no of terms in the document\n",
    "\n",
    "IDF(t) = ln(Total no of documents / No of documents with term t in it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF(t) = TF(t) * IDF(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'brown': 0, u'lazy': 4, u'jumped': 3, u'over': 5, u'fox': 2, u'dog': 1, u'quick': 6, u'the': 7}\n",
      "[1.28768207 1.28768207 1.28768207 1.69314718 1.28768207 1.69314718\n",
      " 1.69314718 1.69314718]\n",
      "(1, 8)\n",
      "[[0.24920411 0.24920411 0.24920411 0.32767345 0.24920411 0.32767345\n",
      "  0.32767345 0.65534691]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# list of text documents\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\",\n",
    "        \"brown dog.\",\n",
    "        \"lazy fox\"]\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "# encode document\n",
    "vector = vectorizer.transform([text[0]])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salary prediction given job description and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'salary-train.csv'\n",
    "test_file = 'salary-test-mini.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    df = pandas.read_csv(filename)\n",
    "    # For beginning, transform train['FullDescription'] to lowercase using text.lower()\n",
    "    # Then replace everything except the letters and numbers to spaces.\n",
    "    # it will facilitate the further division of the text into words.\n",
    "    df['FullDescription'] = df['FullDescription'].str.lower().replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "    \n",
    "    # Replace NaN in LocationNormalized and ContractTime rows to special string 'nan'. \n",
    "    df['LocationNormalized'].fillna('nan', inplace=True)\n",
    "    df['ContractTime'].fillna('nan', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>international sales manager london     k      ...</td>\n",
       "      <td>London</td>\n",
       "      <td>permanent</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an ideal opportunity for an individual that ha...</td>\n",
       "      <td>London</td>\n",
       "      <td>permanent</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>online content and brand manager   luxury reta...</td>\n",
       "      <td>South East London</td>\n",
       "      <td>permanent</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a great local marketleader is seeking a perman...</td>\n",
       "      <td>Dereham</td>\n",
       "      <td>permanent</td>\n",
       "      <td>22500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>registered nurse   rgn  nursing home for young...</td>\n",
       "      <td>Sutton Coldfield</td>\n",
       "      <td>nan</td>\n",
       "      <td>20355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     FullDescription LocationNormalized  \\\n",
       "0  international sales manager london     k      ...             London   \n",
       "1  an ideal opportunity for an individual that ha...             London   \n",
       "2  online content and brand manager   luxury reta...  South East London   \n",
       "3  a great local marketleader is seeking a perman...            Dereham   \n",
       "4  registered nurse   rgn  nursing home for young...   Sutton Coldfield   \n",
       "\n",
       "  ContractTime  SalaryNormalized  \n",
       "0    permanent             33000  \n",
       "1    permanent             50000  \n",
       "2    permanent             40000  \n",
       "3    permanent             22500  \n",
       "4          nan             20355  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = get_data(train_file)\n",
    "train = train[0:1000]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we currently have a vacancy for an hr project ...</td>\n",
       "      <td>Milton Keynes</td>\n",
       "      <td>contract</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a web developer opportunity has arisen with an...</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     FullDescription LocationNormalized  \\\n",
       "0  we currently have a vacancy for an hr project ...      Milton Keynes   \n",
       "1  a web developer opportunity has arisen with an...         Manchester   \n",
       "\n",
       "  ContractTime  SalaryNormalized  \n",
       "0     contract               NaN  \n",
       "1    permanent               NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = get_data(test_file)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1.0\n",
      "  (0, 145)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 145)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 208)\t1.0\n",
      "  (3, 2)\t1.0\n",
      "  (3, 70)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (4, 229)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Convert the collection of raw documents to a matrix of TF-IDF features with TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=5)\n",
    "X_train_tfidf = vectorizer.fit_transform(train['FullDescription'])\n",
    "\n",
    "# Converts the LocationNormalized and ContractTime feature of all records to a list of dictionaries\n",
    "# Eg: [ {'LocationNormalized': 'London', 'Contract': 'Permanent'}, \n",
    "# {'LocationNormalized': 'London', 'Contract': 'Permanent'} ..]\n",
    "features = train[['LocationNormalized', 'ContractTime']].to_dict('records')\n",
    "\n",
    "#Transforms lists of feature-value mappings to vectors\n",
    "enc = DictVectorizer()\n",
    "X_train_categ = enc.fit_transform(features)\n",
    "print X_train_categ[0:5]\n",
    "\n",
    "# Take a sequence of arrays and stack them horizontally to make a single array. \n",
    "# Rebuild arrays divided by scipy.sparse.hstack. \n",
    "# Note that matrices are sparse. \n",
    "# In numerical analysis, a sparse matrix is a matrix in which most of the elements are zero. \n",
    "X_train = hstack([X_train_tfidf,X_train_categ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifier: \n",
    "\n",
    "#classifier = Ridge(alpha=0.1)\n",
    "#classifier = LinearRegression()\n",
    "#classifier = DecisionTreeClassifier()\n",
    "classifer = RandomForestClassifier()\n",
    "# The target value (algorithm has to predict) is SalaryNormalized\n",
    "y = train['SalaryNormalized']\n",
    "\n",
    "# train model on data\n",
    "classifier.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data set\n",
    "X_test_tfidf = vectorizer.transform(test['FullDescription'])\n",
    "X_test_categ = enc.transform(test[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "X_test = hstack([X_test_tfidf, X_test_categ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44724.78444727 46726.26679802]\n"
     ]
    }
   ],
   "source": [
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115281874.88608739\n"
     ]
    }
   ],
   "source": [
    "# Ground truth values were obtained from an online github repo\n",
    "ground_truth = [56541.76, 37190.92]\n",
    "\n",
    "rmse = mean_squared_error(ground_truth, result)\n",
    "print rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
