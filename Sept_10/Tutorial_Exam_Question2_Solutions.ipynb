{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question2: You need to build Logistic Regression from scratch using training set of Titanic dataset. <br>\n",
    "\n",
    "#### Instructions for each cell are provided along with the marks they hold. Fill in the cells with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed value to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the \"train.csv\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train.csv dataset\n",
    "\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all missing rows and columns in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dropna() to remove null values from data\n",
    "\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select following features from dataset. <br>\n",
    "\n",
    "        1. Sex\n",
    "        2. Age\n",
    "        3. Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Sex, Age, Survived features\n",
    "\n",
    "data = data[['Sex', 'Age', 'Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store target 'Survived' in 'y' variable and other variables in 'X'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store 'Survived' in y variable and other variables in X.\n",
    "X = data[['Sex', 'Age']]\n",
    "y = data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Sex column into 1/0 using Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "X['Sex'] = le.fit_transform(X['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into train and test with test size as 20% of total dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert X_train, y_train, X_test, y_test into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "X_test = X_test.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sigmoid function. <br>\n",
    "        \n",
    "           1. Input: An array.\n",
    "           2. Output: Sigmoid of Input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(h, y):\n",
    "\n",
    "    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class for Logistic Regression function. <br>\n",
    "\n",
    "            Input X, y, NumberOfIterations, LearningRate.\n",
    "            Output: Updated weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression(X, y, NumberOfIterations, LearningRate):        \n",
    "   \n",
    "    # Initialize weights randomly\n",
    "    weights = np.random.randn(X.shape[1])\n",
    "        \n",
    "    for i in range(NumberOfIterations):\n",
    "            \n",
    "        # Forward pass\n",
    "        Z = np.dot(X_train, weights)\n",
    "        A = sigmoid(Z)\n",
    "\n",
    "        # Loss Computation\n",
    "        J = loss(A, y)\n",
    "\n",
    "        # Gradient computation\n",
    "        dZ = A - y\n",
    "        dw = np.dot(dZ, X) / X.shape[0]\n",
    "\n",
    "        # Update weights\n",
    "        weights = weights - LearningRate * dw\n",
    "            \n",
    "        # Printing loss after every 100 iterations\n",
    "        if(i % 100 == 0):\n",
    "            print('loss:' + str(J) + '\\t')\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define prediction function. <br>\n",
    "\n",
    "        Input: X, threshold, weights.\n",
    "        Output: Corresponding labels for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, threshold, weights):\n",
    "    return sigmoid(np.dot(X, weights)) >= threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LogisticRegression function with following inputs to train on training set.\n",
    "\n",
    "    1. X_train\n",
    "    2. y_train\n",
    "    3. NumberOfIterations = 1000\n",
    "    4. LearningRate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.1428395529346593\t\n",
      "loss:2.2193106609011375\t\n",
      "loss:1.5701739040113936\t\n",
      "loss:2.24127350355628\t\n",
      "loss:1.5843125894299426\t\n",
      "loss:2.2829341739082194\t\n",
      "loss:4.603213244637438\t\n",
      "loss:1.0966301770145823\t\n",
      "loss:4.630573555897424\t\n",
      "loss:2.3193591435682563\t\n",
      "loss:1.3138644675610744\t\n",
      "loss:1.3812046110489813\t\n",
      "loss:1.5419293977373778\t\n",
      "loss:4.572674079922235\t\n",
      "loss:1.856548424752507\t\n",
      "loss:2.3541686328211497\t\n",
      "loss:1.4653579754063142\t\n",
      "loss:4.623232420929616\t\n",
      "loss:2.368837296908805\t\n",
      "loss:2.39449737321454\t\n"
     ]
    }
   ],
   "source": [
    "# Call  LogisticRegression function and store weights in model.\n",
    "model = LogisticRegression(X_train, y_train, NumberOfIterations=2000, LearningRate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on testing data. Store predictions in preds variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions in preds variable.\n",
    "preds = predict(X_test, 0.8, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.16216216216216"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy = (sum(y_test == preds)/float(len(X_test)))*100\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the reason behind such low accuracy? How can you improve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed half of the dataset while using dropna so data is not sufficient enough to build a accurate model. Using more number of feature set will improve model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
